# ChicagoCrimePrediction
EDA and Predictive Modelling on the Chicago Crime Dataset using PySpark, Hive and storage using HDFS as part of a Big Data project.  


**Abstract:**
We have procured criminal records from the Chicago Police Department’s CLEAR (Citizen Law Enforcement Analysis and Reporting) system. To accomplish our objective of recognizing crime patterns across the city based on geographical locations, we have used Hadoop and Apache Spark to achieve faster data processing and provide near real-time predictive analytics on top of that. The attributes (explained above) comprise the dataset of the system model adopted by our project and will be conducive while plotting the exact locations of the crimes.

By providing a predictive machine learning approach to determine the criminal hotspots and the location, time of committed crimes, people’s awareness can be raised regarding the dangerous locations at certain times. Therefore, this project can potentially help people stay away from the locations at a certain time of the day along with saving lives.

On the other hand, police forces can use this solution to increase the level of crime prediction and prevention. Moreover, this would be useful for police resources allocation. It can help in the distribution of police at most likely crime places for any given time, to grant an efficient usage of police resources. By having all of this information available, we hope to make our community safer for the people living there and also for others who will travel there.

For a sound prediction of the occurrence of a crime at any location and any hour of a day, it is required to consider the consistent data and out of exemptions. Therefore to abstain from false conjectures and guarantee a reliable prediction model, we plan on randomizing the dataset and sampling about 6 million records to train the algorithm.

PS: More details attached in the Project Document
